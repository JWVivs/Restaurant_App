---
title: "EDA"
author: "John Viviani"
date: "5/5/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

c("dplyr",
  "ggplot2",
  "tidyr",
  "stringr", 
  "tidytext",
  "stm",
  "quanteda",
  "tidyverse",
  "fields",
  "cluster",
  "rgl",
  "scales",
  "reshape2" # melt function
  ) -> package_names  
for(package_name in package_names) {
  if(!is.element(package_name, installed.packages()[,1])) {
     install.packages(package_name,
                      repos = "http://cran.mtu.edu/")
  }
  library(package_name, character.only=TRUE,
          quietly=TRUE,verbose=FALSE)
}
rm(list=c("package_name", "package_names")) # clean up the environment

options(scipen = 999)
```

# Reading in Data
```{r}
complete_df <- read.csv("~/COLLEGE/GRAD SCHOOL/Capstone/Restaurant_App/data/processed/complete_df.csv")
complete_df_app <- read.csv("~/COLLEGE/GRAD SCHOOL/Capstone/Restaurant_App/data/processed/complete_df_app.csv")
complete_df_app2 <- read.csv("~/COLLEGE/GRAD SCHOOL/Capstone/Restaurant_App/data/processed/complete_df_app2.csv")

# NYC restaurants added
complete_df_nyc <- read.csv("~/COLLEGE/GRAD SCHOOL/Capstone/Restaurant_App/data/processed/complete_df_nyc.csv")
complete_df_nyc_app <- read.csv("~/COLLEGE/GRAD SCHOOL/Capstone/Restaurant_App/data/processed/complete_df_nyc_app.csv")
complete_df_nyc_app2 <- read.csv("~/COLLEGE/GRAD SCHOOL/Capstone/Restaurant_App/data/processed/complete_df_nyc_app2.csv")
```


# Oyster Price EDA
```{r}
# Filtering for food items that involve oysters
complete_df[grepl("Oyster|oyster", complete_df$Food),] -> oyster_df

# 51 unique restaurants that offer oyster items
unique(oyster_df$Restaurant)
str(oyster_df)

# mean oyster price is $12.74
mean(oyster_df$Price, na.rm = TRUE)

ggplot(data = oyster_df, mapping = aes(x = City, y = Price)) + 
  geom_point() +
  geom_hline(yintercept = mean(oyster_df$Price, na.rm = TRUE),
             size = 0.5, color = "red") + 
  labs(title = "Prices of Oyster Items by City",
       subtitle = "Mean of All Prices")
```


# General Price Menu EDA
```{r}
# mean price for entire menu data is $14.68
mean(complete_df$Price, na.rm = TRUE)

# filtering for mean menu price by city
complete_df %>%
  filter(City == "Boston" | City == "Charleston" | City == "Portland") %>%
  group_by(City) %>%
  summarise(Price = mean(Price, na.rm = TRUE)) -> menu_means

menu_means

ggplot(menu_means, mapping = aes(x = City, y = Price)) + 
  geom_col(color = "black", fill = "dark blue") + 
  ylim(0, 20) + 
  labs(title = "Mean Price of Menu Items by City") + 
  ylab("Price (dollars)")
```
Boston mean menu price is $15.60
Charleston mean menu price is $11.63
Portland mean menu price is $13.01


# Counting Number of Items per Restaurant
```{r}
# number of food items per restaurant (by address to account for franchises)
items_df <- aggregate(cbind(Items = complete_df$Food) ~ complete_df$Address,
                      FUN = function(x){NROW(x)})

# attaching corresponding restaurant name to address
items_df <- merge(items_df, complete_df_app, by.x = "complete_df$Address", by.y = "Address")

# drop column 3
items_df <- items_df[,-3]

# renaming column 1
colnames(items_df)[1] <- "Address"  

# largest to smallest number of items
items_df <- items_df %>%
  arrange(desc(Items))

items_df
```
Boston appears to have more items on their menu on average compared to the other cities (based on the sample of seafood restaurant data I have).


# Topic Modeling with R and Tidy Data Principles
```{r}
library(dplyr)
library(tidyr)
library(stringr)
library(tidytext)

# address instead of restaurant due to franchises
tm_df <- complete_df_nyc %>%
  mutate(Address = factor(Address, levels = unique(Address)))

# text pre-processing
tm_df$Food <- gsub("[^[:alnum:][:space:]]","", tm_df$Food)
tm_df$Food <- tolower(tm_df$Food)

tidy_tm_df <- tm_df %>%
  unnest_tokens(word, Food) %>%
  anti_join(stop_words) %>%
  filter(word != "chicken")

# let's check the most common words
tidy_tm_df %>%
  count(word, sort = TRUE)
# chicken is very common; let's remove as it will negatively impact our topic model

# removing more common words
common_words <- c("chicken", "fried", "shrimp", "salad")

tidy_tm_df2 <- tm_df %>%
  unnest_tokens(word, Food) %>%
  anti_join(stop_words) %>%
  filter(!word %in% common_words)

tidy_tm_df2 %>%
  count(word, sort = TRUE)
```
tidy_tm_df2 gets rid of some more common words as opposed to tidy_tm_df, which should be beneficial for the model going forward.


# Implement Topic Modeling
```{r}
library(stm)
library(quanteda)

menu_dfm <- tidy_tm_df %>% 
  count(Address, word, sort = TRUE) %>%
  cast_dfm(Address, word, n)

# train a topic model
topic_model <- stm(menu_dfm, K = 15, init.type = "Spectral")
summary(topic_model)

# topic model with reduced common words
menu_dfm2 <- tidy_tm_df2 %>%
  count(Address, word, sort = TRUE) %>%
  cast_dfm(Address, word, n)

topic_model2 <- stm(menu_dfm2, K = 15, init.type = "Spectral")
summary(topic_model2)

# topic_model2 with reduced number of topics
topic_model3 <- stm(menu_dfm2, K = 8, init.type = "Spectral")
summary(topic_model3)

# topic_model2 with more topics
topic_model4 <- stm(menu_dfm2, K = 25, init.type = "Spectral")
summary(topic_model4)

# topic_model2 with 5 topics
topic_model5 <- stm(menu_dfm2, K = 5, init.type = "Spectral")
summary(topic_model5)
```
Training a handful of different topic models to look at beta and gamma values, and hopefully make meaningful inferences between each of them.


# Tidying the Topic Model
```{r}
td_beta <- tidy(topic_model)
# beta matrix tells us what are the words that contribute to each topic

td_beta %>%
  group_by(topic) %>%
  top_n(10) %>%
  ungroup %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = topic)) + 
  geom_col(show.legend = FALSE) + 
  facet_wrap(~topic, scales = "free") + 
  coord_flip()
# beta tells us which words contribute the most to which topic

td_gamma <- tidy(topic_model, matrix = "gamma",
                 document_names = rownames(menu_dfm))
# in this document, how much did this topic contribute to it

ggplot(td_gamma, aes(gamma, fill = as.factor(topic))) + 
  geom_histogram(show.legend = FALSE) + 
  facet_wrap(~topic, ncol = 3)
# gamma tells us how likely does this document belong to this topic

### let's use topic_model2 ###
td_beta2 <- tidy(topic_model2)

td_beta2 %>%
  group_by(topic) %>%
  top_n(10) %>%
  ungroup %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = topic)) + 
  geom_col(show.legend = FALSE) + 
  facet_wrap(~topic, scales = "free") + 
  coord_flip()

td_gamma2 <- tidy(topic_model2, matrix = "gamma",
                  document_names = rownames(menu_dfm2))

ggplot(td_gamma2, aes(gamma, fill = as.factor(topic))) + 
  geom_histogram(show.legend = FALSE) + 
  facet_wrap(~topic, ncol = 3)

### let's use topic_model3 ###
td_beta3 <- tidy(topic_model3)

td_beta3 %>%
  group_by(topic) %>%
  top_n(10) %>%
  ungroup %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = topic)) + 
  geom_col(show.legend = FALSE) + 
  facet_wrap(~topic, scales = "free") + 
  coord_flip()

td_gamma3 <- tidy(topic_model3, matrix = "gamma",
                  document_names = rownames(menu_dfm2))

ggplot(td_gamma3, aes(gamma, fill = as.factor(topic))) + 
  geom_histogram(show.legend = FALSE) + 
  facet_wrap(~topic, ncol = 3)

### let's use topic_model4 ###
td_beta4 <- tidy(topic_model4)

td_beta4 %>%
  group_by(topic) %>%
  top_n(10) %>%
  ungroup %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = topic)) + 
  geom_col(show.legend = FALSE) + 
  facet_wrap(~topic, scales = "free") + 
  coord_flip()

td_gamma4 <- tidy(topic_model4, matrix = "gamma",
                  document_names = rownames(menu_dfm2))

ggplot(td_gamma4, aes(gamma, fill = as.factor(topic))) + 
  geom_histogram(show.legend = FALSE) + 
  facet_wrap(~topic, ncol = 3)

### let's use topic_model5 ###
td_beta5 <- tidy(topic_model5)

td_beta5 %>%
  group_by(topic) %>%
  top_n(10) %>%
  ungroup %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = topic)) + 
  geom_col(show.legend = FALSE) + 
  facet_wrap(~topic, scales = "free") + 
  coord_flip()

td_gamma5 <- tidy(topic_model5, matrix = "gamma",
                  document_names = rownames(menu_dfm2))

ggplot(td_gamma5, aes(gamma, fill = as.factor(topic))) + 
  geom_histogram(show.legend = FALSE) + 
  facet_wrap(~topic, ncol = 3)
```
Do the restaurants seem to better fit the topics they're being assigned to in topic_model2? In some restaurants I've looked at, yes. Could be attributed to reducing more of the common words that appear (menu_dfm2).

Try reducing number of topics in next model (topic_model3):

Noticing Seafood, New England, and Steak as cuisine types for topic 3. Food items that contribute the most to topic 3 (crab, grilled, lobster).

Topic 5 consists of mainly these cuisines: 
Pizza, Sandwiches, Seafood, Chicken, Pasta, Wraps, Subs	
American
Italian, Pizza, Seafood, Pasta

Food items that contribute the most to topic 5 (pizza, steak, cheese). Restaurants with high gamma value in this topic seem to fit this topic.

topic_model5:
Topic 5 features lots of Chinese/Asian/Japanese seafood restaurants.

Topic 4 is crab oriented.

Topic 3 has 29 restaurants with a gamma value greater than 0.90.


# Re-shaping td_gamma for Visualization
```{r}
# before reshaping; looking at each topic
ggplot(td_gamma, aes(x = topic, y = gamma)) + 
  geom_point()

# boxplot for topic_model5
td_gamma5$topic <- as.factor(td_gamma5$topic)

ggplot(td_gamma5, aes(x = topic, y = gamma, fill = topic)) + 
  geom_boxplot(outlier.color = "black", outlier.shape = 19,
               outlier.size = 2)

# boxplot for topic_model (original)
td_gamma$topic <- as.factor(td_gamma$topic)

ggplot(td_gamma, aes(x = topic, y = gamma, fill = topic)) + 
  geom_boxplot(outlier.color = "black", outlier.shape = 19,
               outlier.size = 2) + 
  facet_wrap(~topic, ncol = 5)

# converting to a wide data frame
td_gamma_wide <- spread(td_gamma, key = topic, value = gamma)

# gamma for each topic adds up to 1 per restaurant (as they should)
rowSums(td_gamma_wide[, -1])

# topic 3 graph for original topic_model
ggplot(td_gamma_wide, aes(x = document, y = `3`)) + 
  geom_point() + 
  geom_text(aes(label = ifelse(`3` >= 0.50, document, ""), hjust = 1, vjust = 1)) + 
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) + 
  labs(x = "Restaurant",
       y = "Gamma",
       title = "Gamma Values of Restaurants Assigned to Topic 3",
       subtitle = "According to the Original topic_model")

# same thing but for topic_model5
td_gamma_wide5 <- spread(td_gamma5, key = topic, value = gamma)

# gamma for each topic adds up to 1 per restaurant (as they should)
rowSums(td_gamma_wide5[, -1])

# topic 3 graph
ggplot(td_gamma_wide5, aes(x = document, y = `3`)) + 
  geom_point() + 
  geom_text(aes(label = ifelse(`3` >= 0.50, document, ""), hjust = 1, vjust = 1)) + 
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) + 
  labs(x = "Restaurant",
       y = "Gamma",
       title = "Gamma Values of Restaurants Assigned to Topic 3",
       subtitle = "According to topic_model5")
```


# Creating a Euclidean Distance Matrix
```{r}
library(tidyverse)
column_to_rownames(td_gamma_wide, var = "document") -> td_gamma_test

library(fields)
distmatrix <- rdist(td_gamma_test, td_gamma_test)

# kmeans
fit <- kmeans(distmatrix, 15)

# cluster plot
library(cluster)
clusplot(td_gamma_test, fit$cluster,
         color = TRUE, shade = TRUE,
         labels = 2, lines = 0)

# kmeans 2nd fit
fit2 <- kmeans(distmatrix, 5)

# cluster plot (2nd fit)
clusplot(td_gamma_test, fit2$cluster,
         color = TRUE, shade = TRUE,
         labels = 2, lines = 0)

library(rgl)
# include number of clusters in new dataset
newdf <- data.frame(distmatrix, K = fit$cluster)
pcdf <- princomp(distmatrix, cor = TRUE, score = TRUE)
summary(pcdf)

plot(pcdf, type = "lines")

plot3d(pcdf$scores, col = newdf$K)
```
The first kmeans fit uses 15 topics. When clustered, it's a bit straining to look through, so I also made a kmeans that uses only 5 topics.
Note: this originates from our original 'topic_model', which used 'menu_dfm'. 'menu_dfm' did not remove as many common words as 'menu_dfm2', so you will want to test this out on a topic model that uses 'menu_dfm2' as well.


# Hierarchical Clustering
```{r}
# hierarchical clustering
di <- dist(menu_dfm2, method = "euclidean")
tree <- hclust(di, method = "ward.D")
# using restaurant name as label; complete_df_app2 accounts for duped restaurant names with part of address added
par(cex = 0.7)
plot(tree, labels = complete_df_nyc_app2$Restaurant)
rect.hclust(tree, k = 3, border = "red")
```
Franchises (same menu) are clustered together, which is a good sign. Double-checked the distmatrix and their Euclidean distances are properly valued (e.g. franchises with the same menu have distances of 0).


# Adding Restaurant Names to the Distance Matrix
```{r}
td_gamma_wideNames <- td_gamma_wide
# changing column name to match with complete_df_app
colnames(td_gamma_wideNames)[1] <- "Address"

# now we have the correct order of names to add to the distance matrix
td_euc <- merge(td_gamma_wideNames, complete_df_nyc_app2, by = "Address")

# making a dupe of it
distmatrix2 <- distmatrix

# copying these restaurant names
dput(td_euc$Restaurant)

# changing the column names to the corresponding restaurant name
colnames(distmatrix2) <- c("Ostra", "Legal C Bar", "Tracks Raw Bar & Grill", "Aura", "Luke's Lobster 1", 
"Legal Osteria", "City Crab & Seafood Co.", "The Boathouse 10", 
"Hank's Seafood Restaurant", "Legal Sea Foods 100", "Harborside Grill and Patio", 
"The Wayfarer", "North End Grill", "El Palacio Seafood Market", 
"Kipo's", "Dardanel", "Meltemi", "Fuleen Seafood", "Lobster Boat Restaurant", 
"Lox NYC", "Harlow", "Fish Market", "Susan's Fish N Chips", "Le Jardin Bistro", 
"The John Dory Oyster Bar", "Anson", "Oceana", "The Capital Grille", 
"City Lobster & Steakhouse", "Silver Star Restaurant", "Hunt & Fish Club", 
"Estiatorio Milos", "Russ & Daughters Cafe", "Mastro's Steakhouse", 
"Umberto's Clam House", "Atlantic Grill East", "Stockyard", "Boca Chica", 
"Boston Chops", "The Boil", "South Beach Restaurant & Lounge", 
"Live Bait", "Bar Belly", "Morse Fish Company", "Avra", "Lure Fish Bar", 
"Charleston Crab House 145", "Sable's", "Marisco Centro", "Captain Marden's Seafoods", 
"Walter's", "No Name Restaurant", "James Hook & Co Lobsters", 
"Blackstone Grill", "Strip House", "Bubba Gump Shrimp Co.", "Bubba Gump Shrimp Co. 1501", 
"Pearlz Oyster Bar 153", "Flex Mussels", "Flex Mussels 154", 
"Long John Silver's", "Blue Fin", "The Sea Fire Grill", "Francisco's Centro Vasco", 
"Red Hook Lobster Pound", "Central Wharf Co.", "Red Hook Lobster Pound 16", 
"La Pulperia", "Cypress Restaurant", "ZZ's Clam Bar", "Crepes du Nord", 
"Blossom", "Cavatappo Grill", "Cafe Espanol", "Cafe Espanol 172", 
"Himalayan Bistro", "Flex Mussels", "Flex Mussels 174", "Thalassa", 
"JJR Highridge Fishery", "Pearl Oyster Bar", "Claw Daddy's", 
"Phu-Ket Thai Restaurant", "Fleet Landing", "The Tap", "Kellari Taverna", 
"The Crab Shack 1901", "Captain D's 1936", "Mare Seafood", "The Daily Catch 2", 
"The Upper Crust Pizzeria", "Il Pesce", "Tia's", "Anassa Taverna", 
"Pee Dee Steak House", "Wai Cafe", "Amen Street Fish & Rawbar", 
"Clambakes By Jim Sanford", "Luke's Lobster", "Luke's Lobster 207", 
"Cevich", "Miramar", "BLT Fish", "Sparks Steak House", "Iron Sushi", 
"V Bar", "Hyman's Seafood", "The Falmouth Sea Grill", "Ben & Jack's Steakhouse", 
"Ben & Jack's Steakhouse 219", "Pier A", "Pings", "75 on Liberty Wharf", 
"Ed's Lobster Bar", "Fish Tag", "LTK", "The Lobster Shack", "Ed's Lobster Bar Cart", 
"La Gioconda", "Taverna Kyclades", "Jeremy's Ale House", "Bait & Hook", 
"Ricardo Ocean Grill", "Hurley's Saloon", "Joe's Crab Shack", 
"Joe's Crab Shack 2349", "Marea", "Eighteen Restaurant", "Luke's Lobster", 
"Luke's Lobster 242", "Alfredo's Italian Kitchen", "Lighthouse Fish Market & Restaurant", 
"Telio", "Ma Dukes Manhattan Island Seafood", "GaGa Seafood", 
"DiMillo's Floating Restaurant & Marina", "L&W Oyster Co.", "Ben & Jack's Steakhouse", 
"Legal Sea Foods 255", "Ben & Jack's Steakhouse 255", "Legal Sea Foods 26", 
"Off the Boat", "Luke's Lobster", "Four Winds Seafood Grille", 
"Luke's Lobster 26", "East Ocean City", "Saigon Seafood Restaurant", 
"Legal Harborside", "Chicken House", "Brother's Crawfish", "Virgola", 
"Ditch Plains", "Lok Sing Seafood Restaurant", "Waterline", "Charlie Palmer Steak", 
"Joseph's", "Red & Gold Crab Shack", "Yankee Lobster", "Joe's Crab Shack", 
"Joe's Crab Shack 301", "Tulip Indian Restaurant", "Blue Water Grill", 
"Aldea - Quick-Service (Lunch)", "Supreme House of Pizza", "212 Steakhouse", 
"CajunSea", "Bay Kitchen Bar", "The Daily Catch 323", "Asian Diet Food - Broadway", 
"Babalu", "Street & Co.", "Prime 333", "Durgin Park", "La Marina", 
"A W Shuck's Seafood", "Captain Fishbones", "Crown Fried Chicken", 
"Red Hook Lobster Pound", "Alaska Fish Market", "Maloney & Porcelli", 
"The Boathouse 38", "Weathervane Seafood Restaurant", "Amber Sushi (28th St)", 
"Row 34", "Coast", "Burger & Lobster", "Seamore?s Nolita", "Seafood King Fish Market", 
"Sagaponack", "Oceanaire", "Captain D's 4008", "Esca", "Arboretum Pizza Grill", 
"Rincon Limeno Restaurant", "Charleston Crab House 41", "Union Oyster House", 
"Calle 174 Pescaderia (fka Sea Flower)", "The Clam", "Junior's Seafood", 
"Mid Atlantic Fish Market", "Luke's Lobster", "Luke's Lobster 426", 
"Thai North Catering", "Ed's Chowder House", "Fish", "Bubor Cha Cha", 
"Barchetta", "Nick's House of Pizza & Seafood", "Kim's Aunt Kitchen Cart", 
"Albert's Mofongo", "Caridad", "Atlantic Grill Lincoln Center", 
"China Bo ($1 Chinese Rice/#1 Chinese Food)", "East Bay Diner", 
"Fire House Seafood", "New Jumbo Seafood", "J's Oyster", "Jasper White's Summer Shack", 
"Island Creek Oyster Bar", "Locklear's Fine Seafood", "Miel", 
"El Puerto Seafood & Fish Market", "Captain D's 5130", "Benjamin Steakhouse", 
"Hoshiya Sushi", "Three Ocean", "Wild Edibles", "Caviar Russe", 
"Barney Greengrass", "The Boathouse 549", "Nerai", "B&G Oysters", 
"Tommy Bahama", "Legal Crossing", "The Mermaid Inn", "The Mermaid Inn 568", 
"A Taste Of Seafood", "Ichiumi", "Chart House", "Bombay's Indian Restaurant", 
"Sevilla", "Trattoria iL Gusto (Formerly Pesce & Pasta)", "Neptune Oyster", 
"Captain D's 6326", "Docks", "Mary's Fish Camp", "Barfish Bistro", 
"Lorenz Island Kuisine", "New Golden Gate", "Markt Restaurant", 
"Famous Fish Market", "Luke's Lobster", "24 Hour Pizza Delivery", 
"Luke's Lobster 685", "Asian Diet Food - John St.", "Harp Raw Bar & Grill", 
"The Claw", "The Lobster Place", "75 Chestnut", "Luke's Lobster 75", 
"Beluga Bar by Caviarteria", "Royal Roast Beef and Seafood", 
"Black Crescent", "Atlantic Fish Company", "Crispin's", "Grey Lady", 
"Terrace Fish & Chips", "Joon's Westside Fish", "L'Espalier", 
"Cafe Espanol", "Cafe Espanol 78", "Abe & Louie's Steakhouse", 
"Smith & Wollensky", "Boston Sail Loft", "Rosie O'Grady's", "Crab Shack", 
"White Oak", "Thalia", "Chau Chow City", "Huff's Seafood", "The Palm Too", 
"The Crab Shack 8486", "KO Pies", "Cucina Di Pesce", "Molyvos", 
"The Kitchen Sink", "Catch NYC", "Barking Crab", "Bangkok Grand Palace", 
"Grand Central Oyster Bar", "Beekman Beer Garden", "Redeye Grill", 
"Pearlz Oyster Bar 9", "Lobster Smack", "Morton's The Steakhouse", 
"Towne Stove and Spirits", "Gilbert's Chowder House", "Old Port Sea Grill & Raw Bar", 
"Luke's Lobster", "Luke's Lobster 93", "Pisacane Fish & Seafood", 
"Crave Fishbar", "Upstate", "Benvenuto Caffe", "The Mermaid Inn", 
"The Mermaid Inn 96", "El Rey de la Caridad", "Amsterdam Ave Fish", 
"Bubba Gump Shrimp Co. 99", "JJ Sushi Cafe", "McCormick & Schmick's", 
"Urban Lobster Shack On Wheels", "Red Hook Lobster Pound 365", 
"Frying Pan", "North River Lobster Company", "Harbour Lights", 
"The Water Club", "The Crow's Nest")

# likewise for row names
rownames(distmatrix2) <- colnames(distmatrix2)
```
Now that we have our distance matrix properly labeled with the corresponding restaurant names, we can move on to making a data frame featuring the lowest Euclidean distances.


# Creating a Data Frame with the Lowest Euclidean Distances
```{r}
distmatrix_df <- as.data.frame(distmatrix2)
distmatrix_df <- tibble::rownames_to_column(distmatrix_df, "Restaurant")
distmatrix_df[,1] <- colnames(distmatrix2)

# now we need to remove the zeroes, as the franchises are identical to each other (we want different, but similar restaurants)

# need to get df into a long format
longdf <- tibble::rownames_to_column(distmatrix_df, "Similar_Restaurant")
longdf <- melt(longdf)
# changing the column names
longdf <- longdf[,-1]
colnames(longdf)[1] <- "Similar_Restaurant"
colnames(longdf)[2] <- "Restaurant"
colnames(longdf)[3] <- "Distance"

longdf <- merge(longdf, complete_df_nyc_app2, by = "Restaurant")

# getting rid of unnecessary columns
longdf <- longdf[,-4]
# arranging by restaurant and lowest distance
# only care about distances greater than 0 (otherwise we'll get the restaurant being observed as a similar restaurant) 
longdf <- longdf %>% 
  arrange(Restaurant, Distance) %>% 
  filter(Distance > 0)

# getting the top 5 lowest distances
similar <- longdf %>% 
  group_by(Restaurant) %>% 
  top_n(-5, Distance)

# for now... pasting list of the 5 similar restaurant names into a column with the respective restaurant
similar <- aggregate(similar$Similar_Restaurant, list(similar$Restaurant), paste, collapse = ", ")

# renaming columns
colnames(similar)[1] <- "Restaurant"
colnames(similar)[2] <- "Similar_Restaurant"

# merging the similar restaurants with complete_df_app2
sim_rest_df <- merge(similar, complete_df_nyc_app2, by = "Restaurant")

# getting rid of unnecessary columns
sim_rest_df <- sim_rest_df[,-3]

#saveRDS(sim_rest_df, "~/COLLEGE/GRAD SCHOOL/Capstone/Restaurant_App/data/processed/sim_rest_df_nyc")
 
#write.csv(sim_rest_df, "~/COLLEGE/GRAD SCHOOL/Capstone/Restaurant_App/data/processed/sim_rest_df_nyc.csv")

# now we can put this into the app (replace complete_df_app with sim_rest_df_nyc)
```
This works; however, there are couple of issues:

1. Restaurant names have parts of the address appended to them when viewing in the app (this was initially done to help distinguish between which restaurant was being identified regarding franchises)

2. When looking at the most similar restaurants, the franchises will be included (e.g. Restaurant A is most similar to "The Daily Catch #1", "The Daily Catch #2", etc.). Since the franchises have identical menus, we know they will be just as similar to the restaurant we are observing, so we need to remove the duplicates.

Below is the beginning of another distance matrix, but we will be leaving the names as they are (no parts of the address appended to the franchise). This will be beneficial later when integrating into the app.


# Distance Matrix With Restaurant Names as Is
```{r}
# now we have the correct order of names to add to the distance matrix; part of address not added to these restaurant names
td_euc_noadd <- merge(td_gamma_wideNames, complete_df_nyc_app, by = "Address")

# making a dupe of it
distmatrix_noadd <- distmatrix

# copying these restaurant names
dput(td_euc_noadd$Restaurant)

# changing the column names to the corresponding restaurant name
colnames(distmatrix_noadd) <- c("Ostra", "Legal C Bar", "Tracks Raw Bar & Grill", "Aura", "Luke's Lobster", 
"Legal Osteria", "City Crab & Seafood Co.", "The Boathouse", 
"Hank's Seafood Restaurant", "Legal Sea Foods", "Harborside Grill and Patio", 
"The Wayfarer", "North End Grill", "El Palacio Seafood Market", 
"Kipo's", "Dardanel", "Meltemi", "Fuleen Seafood", "Lobster Boat Restaurant", 
"Lox NYC", "Harlow", "Fish Market", "Susan's Fish N Chips", "Le Jardin Bistro", 
"The John Dory Oyster Bar", "Anson", "Oceana", "The Capital Grille", 
"City Lobster & Steakhouse", "Silver Star Restaurant", "Hunt & Fish Club", 
"Estiatorio Milos", "Russ & Daughters Cafe", "Mastro's Steakhouse", 
"Umberto's Clam House", "Atlantic Grill East", "Stockyard", "Boca Chica", 
"Boston Chops", "The Boil", "South Beach Restaurant & Lounge", 
"Live Bait", "Bar Belly", "Morse Fish Company", "Avra", "Lure Fish Bar", 
"Charleston Crab House", "Sable's", "Marisco Centro", "Captain Marden's Seafoods", 
"Walter's", "No Name Restaurant", "James Hook & Co Lobsters", 
"Blackstone Grill", "Strip House", "Bubba Gump Shrimp Co.", "Peix Bar de Mariscos", 
"Pearlz Oyster Bar", "Flex Mussels", "Le Bernardin", "Long John Silver's", 
"Blue Fin", "The Sea Fire Grill", "Francisco's Centro Vasco", 
"Red Hook Lobster Pound", "Central Wharf Co.", "St. Nicholas Fish Market", 
"La Pulperia", "Cypress Restaurant", "ZZ's Clam Bar", "Crepes du Nord", 
"Blossom", "Cavatappo Grill", "Cafe Espanol", "Jeffrey's Grocery", 
"Himalayan Bistro", "Flex Mussels", "Crudo Vineria con Cucina", 
"Thalassa", "JJR Highridge Fishery", "Pearl Oyster Bar", "Claw Daddy's", 
"Phu-Ket Thai Restaurant", "Fleet Landing", "The Tap", "Kellari Taverna", 
"The Crab Shack", "Captain D's", "Mare Seafood", "The Daily Catch", 
"The Upper Crust Pizzeria", "Il Pesce", "Tia's", "Anassa Taverna", 
"Pee Dee Steak House", "Wai Cafe", "Amen Street Fish & Rawbar", 
"Clambakes By Jim Sanford", "Luke's Lobster", "Fish & Shrimp", 
"Cevich", "Miramar", "BLT Fish", "Sparks Steak House", "Iron Sushi", 
"V Bar", "Hyman's Seafood", "The Falmouth Sea Grill", "Ben & Jack's Steakhouse", 
"Harlem Savour of Seafood Inc", "Pier A", "Pings", "75 on Liberty Wharf", 
"Ed's Lobster Bar", "Fish Tag", "LTK", "The Lobster Shack", "Ed's Lobster Bar Cart", 
"La Gioconda", "Taverna Kyclades", "Jeremy's Ale House", "Bait & Hook", 
"Ricardo Ocean Grill", "Hurley's Saloon", "Joe's Crab Shack", 
"Empire Steak House", "Marea", "Eighteen Restaurant", "Luke's Lobster", 
"Murray's Sturgeon Shop", "Alfredo's Italian Kitchen", "Lighthouse Fish Market & Restaurant", 
"Telio", "Ma Dukes Manhattan Island Seafood", "GaGa Seafood", 
"DiMillo's Floating Restaurant & Marina", "L&W Oyster Co.", "Ben & Jack's Steakhouse", 
"Legal Sea Foods", "Cowgirl SeaHorse", "Legal Sea Foods", "Off the Boat", 
"Luke's Lobster", "Four Winds Seafood Grille", "Claw", "East Ocean City", 
"Saigon Seafood Restaurant", "Legal Harborside", "Chicken House", 
"Brother's Crawfish", "Virgola", "Ditch Plains", "Lok Sing Seafood Restaurant", 
"Waterline", "Charlie Palmer Steak", "Joseph's", "Red & Gold Crab Shack", 
"Yankee Lobster", "Joe's Crab Shack", "LoLo's Seafood Shack", 
"Tulip Indian Restaurant", "Blue Water Grill", "Aldea - Quick-Service (Lunch)", 
"Supreme House of Pizza", "212 Steakhouse", "CajunSea", "Bay Kitchen Bar", 
"The Daily Catch", "Asian Diet Food - Broadway", "Babalu", "Street & Co.", 
"Prime 333", "Durgin Park", "La Marina", "A W Shuck's Seafood", 
"Captain Fishbones", "Crown Fried Chicken", "Red Hook Lobster Pound", 
"Alaska Fish Market", "Maloney & Porcelli", "The Boathouse", 
"Weathervane Seafood Restaurant", "Amber Sushi (28th St)", "Row 34", 
"Coast", "Burger & Lobster", "Seamore?s Nolita", "Seafood King Fish Market", 
"Sagaponack", "Oceanaire", "Captain D's", "Esca", "Arboretum Pizza Grill", 
"Rincon Limeno Restaurant", "Charleston Crab House", "Union Oyster House", 
"Calle 174 Pescaderia (fka Sea Flower)", "The Clam", "Junior's Seafood", 
"Mid Atlantic Fish Market", "Luke's Lobster", "House of Seafood Express", 
"Thai North Catering", "Ed's Chowder House", "Fish", "Bubor Cha Cha", 
"Barchetta", "Nick's House of Pizza & Seafood", "Kim's Aunt Kitchen Cart", 
"Albert's Mofongo", "Caridad", "Atlantic Grill Lincoln Center", 
"China Bo ($1 Chinese Rice/#1 Chinese Food)", "East Bay Diner", 
"Fire House Seafood", "New Jumbo Seafood", "J's Oyster", "Jasper White's Summer Shack", 
"Island Creek Oyster Bar", "Locklear's Fine Seafood", "Miel", 
"El Puerto Seafood & Fish Market", "Captain D's", "Benjamin Steakhouse", 
"Hoshiya Sushi", "Three Ocean", "Wild Edibles", "Caviar Russe", 
"Barney Greengrass", "The Boathouse", "Nerai", "B&G Oysters", 
"Tommy Bahama", "Legal Crossing", "The Mermaid Inn", "Pudgie's/Nathans/Arthur Treacher's", 
"A Taste Of Seafood", "Ichiumi", "Chart House", "Bombay's Indian Restaurant", 
"Sevilla", "Trattoria iL Gusto (Formerly Pesce & Pasta)", "Neptune Oyster", 
"Captain D's", "Docks", "Mary's Fish Camp", "Barfish Bistro", 
"Lorenz Island Kuisine", "New Golden Gate", "Markt Restaurant", 
"Famous Fish Market", "Luke's Lobster", "24 Hour Pizza Delivery", 
"Villa Mosconi", "Asian Diet Food - John St.", "Harp Raw Bar & Grill", 
"The Claw", "The Lobster Place", "75 Chestnut", "Luke's Lobster", 
"Beluga Bar by Caviarteria", "Royal Roast Beef and Seafood", 
"Black Crescent", "Atlantic Fish Company", "Crispin's", "Grey Lady", 
"Terrace Fish & Chips", "Joon's Westside Fish", "L'Espalier", 
"Cafe Espanol", "Mermaid Oyster Bar", "Abe & Louie's Steakhouse", 
"Smith & Wollensky", "Boston Sail Loft", "Rosie O'Grady's", "Crab Shack", 
"White Oak", "Thalia", "Chau Chow City", "Huff's Seafood", "The Palm Too", 
"The Crab Shack", "KO Pies", "Cucina Di Pesce", "Molyvos", "The Kitchen Sink", 
"Catch NYC", "Barking Crab", "Bangkok Grand Palace", "Grand Central Oyster Bar", 
"Beekman Beer Garden", "Redeye Grill", "Pearlz Oyster Bar", "Lobster Smack", 
"Morton's The Steakhouse", "Towne Stove and Spirits", "Gilbert's Chowder House", 
"Old Port Sea Grill & Raw Bar", "Luke's Lobster", "Ashiya V Sushi", 
"Pisacane Fish & Seafood", "Crave Fishbar", "Upstate", "Benvenuto Caffe", 
"The Mermaid Inn", "Montes Trattoria", "El Rey de la Caridad", 
"Amsterdam Ave Fish", "Bubba Gump Shrimp Co.", "JJ Sushi Cafe", 
"McCormick & Schmick's", "Urban Lobster Shack On Wheels", "Grand Banks", 
"Frying Pan", "North River Lobster Company", "Harbour Lights", 
"The Water Club", "The Crow's Nest")
```
Now we need to make the row names match the column names. It wouldn't let me do this in its matrix format, so I'll convert it to a data frame and work on it from there.


# Data Frame with Lowest Euclidean Distances & No Repeated Restaurants
```{r}
distmatrix_noadd_df <- as.data.frame(distmatrix_noadd)
distmatrix_noadd_df <- tibble::rownames_to_column(distmatrix_noadd_df, "Restaurant")
distmatrix_noadd_df[,1] <- colnames(distmatrix_noadd)

# now we need to remove the zeroes, as the franchises are identical to each other (we want different, but similar restaurants)

# need to get df into a long format
longdf_noadd <- tibble::rownames_to_column(distmatrix_noadd_df, "Similar_Restaurant")
longdf_noadd <- melt(longdf_noadd)
# changing the column names
longdf_noadd <- longdf_noadd[,-1]
colnames(longdf_noadd)[1] <- "Similar_Restaurant"
colnames(longdf_noadd)[2] <- "Restaurant"
colnames(longdf_noadd)[3] <- "Distance"

longdf_noadd <- merge(longdf_noadd, complete_df_nyc_app, by = "Restaurant")

# getting rid of unnecessary columns
longdf_noadd <- longdf_noadd[,-4]

# gets rid of repeated franchises in Similar_Restaurants
longdf_noadd <- longdf_noadd %>% 
  distinct(Restaurant, Similar_Restaurant, Distance, .keep_all = TRUE)

# arranging by restaurant and lowest distance
# only care about distances greater than 0 (otherwise we'll get the restaurant being observed as a similar restaurant)
longdf_noadd <- longdf_noadd %>% 
  arrange(Restaurant, Distance) %>% 
  filter(Distance > 0)

# getting the top 5 lowest distances
similar_noadd <- longdf_noadd %>% 
  group_by(Restaurant) %>% 
  top_n(-5, Distance)

# for now... pasting list of the 5 similar restaurant names into a column with the respective restaurant
similar_noadd <- aggregate(similar_noadd$Similar_Restaurant, list(similar_noadd$Restaurant), paste, collapse = ", ")

# renaming columns
colnames(similar_noadd)[1] <- "Restaurant"
colnames(similar_noadd)[2] <- "Similar_Restaurant"

# merging the similar restaurants with complete_df_app2
sim_rest_df_noadd <- merge(similar_noadd, complete_df_nyc_app, by = "Restaurant")

# getting rid of unnecessary columns
sim_rest_df_noadd <- sim_rest_df_noadd[,-3]

#saveRDS(sim_rest_df_noadd, "~/COLLEGE/GRAD SCHOOL/Capstone/Restaurant_App/data/processed/sim_rest_df_noadd")
 
#write.csv(sim_rest_df_noadd, "~/COLLEGE/GRAD SCHOOL/Capstone/Restaurant_App/data/processed/sim_rest_df_noadd.csv")
```
sim_rest_df_noadd should serve as the final, and complete data frame for use in the app. It features no duplicates in Similar_Restaurants when we are observing the lowest Euclidean distances, and all of the restaurant names are as is (parts of the address not attached).


# Count of Euclidean Distances
```{r}
longdf_distCount <- longdf_noadd %>% 
  group_by(Restaurant) %>% 
  filter(Distance > 0 & Distance < 0.15) %>% 
  mutate(Count = n())

# pasting list of the similar restaurant names into a column with the respective restaurant
distCount <- aggregate(longdf_distCount$Similar_Restaurant, list(longdf_distCount$Restaurant), paste, collapse = ", ")

# renaming columns
colnames(distCount)[1] <- "Restaurant"
colnames(distCount)[2] <- "Similar_Restaurant"

# gets rid of repeated franchises in Similar_Restaurants
distinctCount <- longdf_distCount %>% 
  distinct(Restaurant, Count, .keep_all = TRUE)

# merging the Count column with distCount
eucdistCount <- merge(distinctCount, distCount, by = "Restaurant")

# removing unnecessary columns
eucdistCount <- eucdistCount[,-c(2:3)]

# fixing column name
colnames(eucdistCount)[8] <- "Similar_Restaurant"

# reordering columns
eucdistCount <- eucdistCount[,c(1,8,7,2,3,4,5,6)]

#saveRDS(eucdistCount, "~/COLLEGE/GRAD SCHOOL/Capstone/Restaurant_App/data/processed/eucdistCount")
```
The idea here is to generate a column that has a count for each restaurant regarding the number of times they have a Euclidean distance under a certain number. The restaurant with highest count would be considered the most similar to the list of restaurants used.




## Prior Use

# Latent Dirichlet Allocation (LDA)
```{r}
#https://rpubs.com/Junny31/318845
library(tm)
library(SnowballC)

# creating a corpus
text_corpus <- VCorpus(VectorSource(complete_df$Food))

print(text_corpus)

# text preparation
text_corpus_clean <- tm_map(text_corpus, content_transformer(tolower)) %>%
  tm_map(., stemDocument) %>%
  tm_map(., removeNumbers) %>%
  tm_map(., removeWords, stopwords()) %>%
  tm_map(., removePunctuation) %>%
  tm_map(., stripWhitespace)


library(wordcloud)
# plot words with a minimum frequency of 20
wordcloud(text_corpus_clean, min.freq = 20, random.order = FALSE,
          colors=brewer.pal(8, "Dark2"))

# model training
text_dtm <- DocumentTermMatrix(text_corpus_clean)
text_dtm

findFreqTerms(text_dtm, lowfreq = 20)

# each row of the input matrix needs to contain at least one non-zero entry
ui = unique(text_dtm$i)
text_dtm.new = text_dtm[ui,]

library(topicmodels)

text_lda <- LDA(text_dtm.new, k = 30, method = "VEM", control = NULL)
text_lda

# model evaluation
library(tidytext)

text_topics <- tidy(text_lda, matrix = "beta")

text_topics

library(ggplot2)
library(dplyr)

text_top_terms <- text_topics %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

text_top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()
```


# More with LDA
```{r}
# https://towardsdatascience.com/beginners-guide-to-lda-topic-modelling-with-r-e57a5a8e7a25
library(textmineR)

# just want the food items
foodItems <- as.data.frame(complete_df[,5])
colnames(foodItems)[1] <- "Food"

# text pre-processing
foodItems <- as.data.frame(gsub("[^[:alnum:][:space:]]","", foodItems$Food))
colnames(foodItems)[1] <- "Food"

# create document term matrix
dtm <- CreateDtm(foodItems$Food,
                 ngram_window = c(1, 2))

# explore the basic frequency
tf <- TermDocFreq(dtm = dtm)
original_tf <- tf %>% select(term, term_freq, doc_freq)
rownames(original_tf) <- 1:nrow(original_tf)

# Eliminate words appearing less than 2 times or in more than half of the documents
vocabulary <- tf$term[tf$term_freq > 1 & tf$doc_freq < nrow(dtm) / 2]

dtm = dtm

# model building
model <- FitLdaModel(dtm = dtm, k = 8, iterations = 100)

coherence_df <- as.data.frame(model$coherence)

coherence_df$id <- row.names(coherence_df)

# plotting coherence score
ggplot(coherence_df, aes(x = id, y = model$coherence)) +
  geom_point() +
  geom_line(group = 1)+
  ggtitle("Best Topic by Coherence Score") + theme_minimal() +
  ylab("Coherence") + 
  xlab("k") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
# topic 2 has the best coherence score

# top 20 terms to best describe the topic
model$top_terms <- GetTopTerms(phi = model$phi, M = 20)
top20_wide <- as.data.frame(model$top_terms)

# hierarchical clustering of the topics
model$topic_linguistic_dist <- CalcHellingerDist(model$phi)

model$hclust <- hclust(as.dist(model$topic_linguistic_dist), "ward.D")
model$hclust$labels <- paste(model$hclust$labels, model$labels[,1])

plot(model$hclust)
```

k = 2 yields the highest coherence score. In other words, the model believes that the words in topic 2 are most semantically similar among the 20 topics.


# Text Analysis with quanteda
```{r}
#https://data.library.virginia.edu/a-beginners-guide-to-text-analysis-with-quanteda/
library(quanteda)

# just want the food items and an id column
foodItems <- as.data.frame(complete_df[,c(2,5)])
colnames(foodItems)[1] <- "id"

# text pre-processing
foodItems$Food <- gsub("[^[:alnum:][:space:]]","", foodItems$Food)

# creating a corpus
doc.corpus <- corpus(foodItems$Food)
summary(doc.corpus)

# cleaning and creating tokens
doc.tokens <- tokens(doc.corpus)
doc.tokens <- tokens(doc.tokens, remove_punct = TRUE, 
                     remove_numbers = TRUE)
# removing stop words
doc.tokens <- tokens_select(doc.tokens, stopwords('english'),selection='remove')
# stem (reduce each word down to its base form) the tokens
doc.tokens <- tokens_wordstem(doc.tokens)
# convert to lowercase
doc.tokens <- tokens_tolower(doc.tokens)

# converting to a document feature matrix
doc.dfm <- dfm(doc.corpus, remove_numbers = TRUE,
               stem = TRUE,
               remove = stopwords("english"))
# use previously created tokenized object as dfm to be safe
doc.dfm.final <- dfm(doc.tokens)

# look at certain words
View(head(kwic(doc.tokens, "shrimp", window = 3)))

# looking at the top 5 words
topfeatures(doc.dfm.final, 5)

# top 20 words
list_top20 <- rownames(as.data.frame(topfeatures(doc.dfm.final, 20)))

View(kwic(doc.tokens, list_top20, window = 3))

corpus_dictionary <- as.data.frame(kwic(doc.corpus, list_top20))

# top 50 words
topfeatures(doc.dfm.final, 50)
list_top50 <- rownames(as.data.frame(topfeatures(doc.dfm.final, 50)))

dictionary_50 <- kwic(doc.tokens, list_top50, window = 3)

View(kwic(doc.tokens, list_top50, window = 3))
```


# https://github.com/bmschmidt/wordVectors/blob/master/vignettes/introduction.Rmd
```{r}
if (!require(wordVectors)) {
  if (!(require(devtools))) {
    install.packages("devtools")
  }
  devtools::install_github("bmschmidt/wordVectors")
}

library(wordVectors)
library(magrittr)

if (!file.exists("cookbooks.zip")) {
  download.file("http://archive.lib.msu.edu/dinfo/feedingamerica/cookbook_text.zip","cookbooks.zip")
}
unzip("cookbooks.zip",exdir="cookbooks")

if (!file.exists("cookbooks.txt")) prep_word2vec(origin="cookbooks",destination="cookbooks.txt",lowercase=T,bundle_ngrams=2)

# training
if (!file.exists("cookbook_vectors.bin")) {model = train_word2vec("cookbooks.txt","cookbook_vectors.bin",vectors=200,threads=4,window=12,iter=5,negative_samples=0)} else model = read.vectors("cookbook_vectors.bin")
```


# applying to my data
```{r}
library(wordVectors)
# reading in the model
model <- readRDS("./models/word2vec_model.rds")

test <- complete_df

# text pre-processing
test$Food <- gsub("[^[:alnum:][:space:]]","", test$Food)
test$Food <- tolower(test$Food)

test_df <- test[5]

# saving as a txt file
#write.table(test_df,"food.txt",sep="\t",row.names=FALSE)

# training
model <- train_word2vec("./food.txt")
#saveRDS(model, file = "~/COLLEGE/GRAD SCHOOL/Capstone/Restaurant_App/code/EDA/models/word2vec_model.rds")

# similarity searches
model %>% 
  closest_to(model[[c("fish","salmon","trout","shad","flounder","carp","roe","eels")]], 50)

some_fish = closest_to(model,model[[c("fish","salmon","trout","shad","flounder","carp","roe","eels")]],150)
fishy = model[[some_fish$word,average=F]]
plot(fishy,method="pca")

# clustering
clustering = kmeans(model, centers = 150, iter.max = 40)

sapply(sample(1:150,10), function(n) {
  names(clustering$cluster[clustering$cluster==n][1:10])
})

# take the 20 words closest to each of four different kinds of words
ingredients = c("madeira","beef","saucepan","carrots")
term_set = lapply(ingredients, 
       function(ingredient) {
          nearest_words = model %>% closest_to(model[[ingredient]],20)
          nearest_words$word
        }) %>% unlist
subset = model[[term_set,average=F]]
subset %>%
  cosineDist(subset) %>% 
  as.dist %>%
  hclust %>%
  plot

# # find 20 words most similar to "sweet" and "salty"
# tastes = model[[c("sweet","salty"),average=F]]
# # model[1:100,] here restricts to the 1000 most common words in the set.
# sweet_and_saltiness = model[1:1000,] %>% cosineSimilarity(tastes)
# # Filter to the top 20 sweet or salty.
# sweet_and_saltiness = sweet_and_saltiness[
#   rank(-sweet_and_saltiness[,1])<20 |
#   rank(-sweet_and_saltiness[,2])<20,
#   ]
# plot(sweet_and_saltiness,type='n')
# text(sweet_and_saltiness,labels=rownames(sweet_and_saltiness))

# catchall reduction: TSNE
library(tsne)

plot(model, perplexity = 7)
```
read in a previously trained model with `model =  read.vectors("cookbook_vectors.bin")`


# trying to cluster the restaurants
```{r}
library(cluster)
library(fpc)

kmeans(menu_dfm2, centers = 5) -> test
plotcluster(menu_dfm2, test$cluster)

### document clustering ###
library(textmineR)

# get IDF vector as a data frame
tf_mat <- TermDocFreq(menu_dfm2)

# TF-IDF and cosine similarity
tfidf <- t(menu_dfm2[ , tf_mat$term]) * tf_mat$idf

# calculate cosine similarity
csim <- tfidf / sqrt(rowSums(tfidf * tfidf))

csim <- csim %*% t(csim)

# convert cosine similarity to distance by subtracting it from 1
cdist <- as.dist(1 - csim)

# clustering
hc <- hclust(cdist, "ward.D")
plot(hc)

```

