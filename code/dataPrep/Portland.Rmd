---
title: "Portland"
author: "John Viviani"
date: "4/13/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(rvest)
library(tidyr)
```

Let's repeat the process for another city (Portland, Maine)

# Scraped Data from allmenus.com
This data was scraped, then organized into a dataframe.
I searched for seafood restaurants in Portland, ME.
Used SelectorGadget (chrome extension) to get CSS elements.
```{r}
site_portland <- read_html("https://www.allmenus.com/me/portland/-/seafood/")

# scraping the restaurant names
site_portland %>%
  html_nodes(".name a") %>%
  html_text() %>% 
  as.data.frame() -> df_names

# scraping the restaurant cuisines
site_portland %>%
  html_nodes(".cousine-list") %>%
  html_text() %>% 
  as.data.frame() -> df_cuisine

# scraping the address
site_portland %>%
  html_nodes(".delivery+ .address") %>%
  html_text() %>% 
  as.data.frame() -> df_address

# scraping the city, state, and zip
site_portland %>%
  html_nodes(".address+ .address") %>%
  html_text() %>%
  as.data.frame() -> df_location

# combining all of these into one data frame
cbind(df_names, df_cuisine, df_address, df_location) -> df_portland

# naming the columns
names(df_portland) <- c("Restaurant", "Cuisine", "Address", "Location")

# merge location and address columns together
df_portland$Address <- paste(df_portland$Address, df_portland$Location)

# dropping the old location column
df_portland %>%
  select(., -contains("Location")) -> df_portland

# removing duplicated restaurants based on address
df_portland <- subset(df_portland, !duplicated(df_portland[,1]))

# saving for map usage later
write.csv(df_portland, "C:/Users/JVivs/Documents/COLLEGE/GRAD SCHOOL/Capstone/Restaurant_App/data/raw/df_portland.csv")
```


# Scraping menu data (found once you click restaurant name link)
Few different functions to get each item into its own list. Later converted to data frames and merged into one.
```{r}
s <- html_session("https://www.allmenus.com/me/portland/-/seafood/")

link <- as.vector(df_portland$Restaurant, mode = "character")
n <- length(link) # number of restaurant names
# function to get each food item from each restaurant
food <- list()
for (i in 1:n){

    s <- s %>% follow_link(link[i])
    food[[(i)]] <- s %>% 
      html_nodes(".item-title") %>%
      html_text()
    s <- s %>% back()}

# converting list to a data frame
sapply(food, '[', seq(max(sapply(food, length)))) -> food_df_portland
as.data.frame(food_df_portland) -> food_df_portland

# adding names to each column
names(food_df_portland) <- link

# function to get each price for each food item from each restaurant
price <- list()
for (i in 1:n){

    s <- s %>% follow_link(link[i])
    price[[(i)]] <- s %>% 
      html_nodes(".item-price") %>%
      html_text()
    s <- s %>% back()}

# converting list to a data frame
sapply(price, '[', seq(max(sapply(price, length)))) -> price_df_portland
as.data.frame(price_df_portland) -> price_df_portland

# adding names to each column
names(price_df_portland) <- link

# converting from wide to long data frame and removing NAs
food_df_portland <- food_df_portland[, !duplicated(colnames(food_df_portland))]
price_df_portland <- price_df_portland[, !duplicated(colnames(price_df_portland))]

gather(food_df_portland, key = "Restaurant", value = "Food", link) -> food_long_portland
na.omit(food_long_portland) -> food_long_portland

gather(price_df_portland, key = "Restaurant", value = "Price", link) -> price_long_portland
na.omit(price_long_portland) -> price_long_portland

# clean the price df
price_long_portland$Price <- gsub(" ", "", price_long_portland$Price)
# removing '$', but using as.character to keep '+'.
price_long_portland$Price <-  as.character(gsub("[\\$,]", "", price_long_portland$Price))

# merge food and price data frames together
final_df_portland <- cbind(food_long_portland, price_long_portland)

# dropping the extra restaurant column
final_df_portland <- final_df_portland[-3]

# merging df_portland and final_df so that menu and location data are in one data frame
portland <- merge.data.frame(final_df_portland, df_portland, all.x = TRUE)
```

Now we need to retrieve the latitude and longitude for the addresses in the 'portland' data frame.

Managed to retrieve coordinates by using the google sheets add-on "Geocode by Awesome Table". I uploaded a sheet of addresses, and it gave me the latitude and longitude for each. I saved this sheet as a .csv file and read it back into R.

# Geocoding
```{r}
# Copying addresses to my clipboard to use in Google Sheets
#writeClipboard(df_portland$Address)

# Reading back in the coordinate data
portland_add <- read.csv("C:/Users/JVivs/Documents/COLLEGE/GRAD SCHOOL/Capstone/Restaurant_App/data/raw/portland_addresses.csv")

# Updating the df with latitude and longitude columns
portland_final <- merge.data.frame(portland, portland_add, all.x = TRUE)

# saving portland_final df
write.csv(portland_final, "C:/Users/JVivs/Documents/COLLEGE/GRAD SCHOOL/Capstone/Restaurant_App/data/processed/portland_final.csv")
```

Now I need to combine this data with the Boston data to make a collective map.
